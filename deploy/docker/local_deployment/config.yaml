######################################################################################################
# SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
######################################################################################################
---
summarization:
  enable: true
  method: "batch"
  llm:
    model: "meta/llama-3.1-70b-instruct"
    base_url: "http://host.docker.internal:8000/v1" #FIXME - update url to running LLM Instance
    max_tokens: 2048
    temperature: 0.2
    top_p: 0.7
  embedding:
    model: "nvidia/llama-3.2-nv-embedqa-1b-v2"
    base_url: "http://host.docker.internal:9234/v1" #FIXME - update url to running embedding NIM instance
  params:
    batch_size: 5
    batch_max_concurrency: 20
  prompts:
    caption: "For each frame of the video, produce a detailed caption prefixed with the frame's timestamp in seconds. Describe all visible objects, actions and prominent colors. If audio is present, include any relevant sounds or speech for that timestamp. Use the format `timestamp: description`."
    caption_summarization: "Summarize the frame-by-frame captions into bullet points in the format start_time:end_time: detailed_event_description. Use '.' to separate hours, minutes and seconds. Ignore routine activity and focus on noteworthy events. Only output the bullet points."
    summary_aggregation: "You are a warehouse monitoring system. Given the caption in the form start_time:end_time: caption, Aggregate the following captions in the format start_time:end_time:event_description. If the event_description is the same as another event_description, aggregate the captions in the format start_time1:end_time1,...,start_timek:end_timek:event_description. If any two adjacent end_time1 and start_time2 is within a few tenths of a second, merge the captions in the format start_time1:end_time2. The output should only contain bullet points.  Cluster the output into Unsafe Behavior, Operational Inefficiencies, Potential Equipment Damage and Unauthorized Personnel"

chat:
  rag: graph-rag # graph-rag or vector-rag #If using a small LLM model, vector-rag is recommended.
  params:
    batch_size: 1
    top_k: 5
  llm:
    model: "meta/llama-3.1-70b-instruct"
    base_url: "http://host.docker.internal:8000/v1" #FIXME - update url to running LLM Instance
    max_tokens: 2048
    temperature: 0.2
    top_p: 0.7
  embedding:
    model: "nvidia/llama-3.2-nv-embedqa-1b-v2"
    base_url: "http://host.docker.internal:9234/v1" #FIXME - update url to running embedding NIM Instance
  reranker:
    model: "nvidia/llama-3.2-nv-rerankqa-1b-v2"
    base_url: "http://host.docker.internal:9235/v1" #FIXME - update url to running reranker NIM Instance

notification:
  enable: true
  endpoint: "http://host.docker.internal:60000/via-alert-callback"
  llm:
    model: "meta/llama-3.1-70b-instruct"
    base_url: "http://host.docker.internal:8000/v1" #FIXME - update url to running LLM Instance
    max_tokens: 2048
    temperature: 0.2
    top_p: 0.7